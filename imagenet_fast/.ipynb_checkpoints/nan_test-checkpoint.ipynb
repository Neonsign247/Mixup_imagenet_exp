{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:***************************** LOGISTICS *****************************\n",
      "INFO:root:Experiment Date: 2022-10-23 02:30\n",
      "INFO:root:Output Name: fast_adv\n",
      "INFO:root:User: None\n"
     ]
    }
   ],
   "source": [
    "# This module is adapted from https://github.com/mahyarnajibi/FreeAdversarialTraining/blob/master/main_free.py\n",
    "# Which in turn was adapted from https://github.com/pytorch/examples/blob/master/imagenet/main.py\n",
    "import init_paths\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from validation import validate\n",
    "#import torchvision.models as models\n",
    "import models\n",
    "from models.imagenet_resnet import BasicBlock, Bottleneck\n",
    "from multiprocessing import Pool\n",
    "#from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "import pdb\n",
    "import wandb\n",
    "import random\n",
    "\n",
    "\n",
    "from apex import amp\n",
    "import copy\n",
    "\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='PyTorch ImageNet Training')\n",
    "    parser.add_argument('--data', \n",
    "                        type=str,\n",
    "                        default='/workspace/dataset/ILSVRC2012-sz/352',\n",
    "                        metavar='DIR', help='path to dataset')\n",
    "    parser.add_argument('--output_prefix',\n",
    "                        default='fast_adv',\n",
    "                        type=str,\n",
    "                        help='prefix used to define output path')\n",
    "    parser.add_argument('-c',\n",
    "                        '--config',\n",
    "                        default='configs/cutmix_d1.0/configs_fast_phase3.yml',\n",
    "                        type=str,\n",
    "                        metavar='Path',\n",
    "                        help='path to the config file (default: configs.yml)')\n",
    "    parser.add_argument('--resume',\n",
    "                        default='./trained_models/vanilla_test2_phase2/checkpoint_epoch40.pth.tar',\n",
    "                        type=str,\n",
    "                        metavar='PATH',\n",
    "                        help='path to latest checkpoint (default: none)')\n",
    "    parser.add_argument('-e',\n",
    "                        '--evaluate',\n",
    "                        dest='evaluate',\n",
    "                        action='store_true',\n",
    "                        help='evaluate model on validation set')\n",
    "    parser.add_argument('--pretrained',\n",
    "                        dest='pretrained',\n",
    "                        action='store_true',\n",
    "                        help='use pre-trained model')\n",
    "    parser.add_argument('--restarts', default=1, type=int)\n",
    "    return parser.parse_args(args = [])\n",
    "\n",
    "\n",
    "# Parase config file and initiate logging\n",
    "# args = parser.parse_args(args = [])\n",
    "configs = parse_config_file(parse_args())\n",
    "logger = initiate_logger(configs.output_name, configs.evaluate)\n",
    "print = logger.info\n",
    "cudnn.benchmark = True\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "criterion_batch = nn.CrossEntropyLoss(reduction='none').cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:***************************** ARGUMENTS *****************************\n",
      "INFO:root:TRAIN: {'arch': 'resnet50', 'lr': 0.1, 'momentum': 0.9, 'weight_decay': 0.0001, 'print_freq': 100, 'mean': [0.485, 0.456, 0.406], 'std': [0.229, 0.224, 0.225], 'start_epoch': 40, 'epochs': 100, 'lr_epochs': [40, 65, 90, 100], 'lr_values': [0.02, 0.002, 0.0002, 2e-05], 'clean_lam': 0, 'alpha': 1, 'ratio': 1.0, 'beta': 1.5, 'eps': 0.8, 'eta': 0.2, 'mp': 8}\n",
      "INFO:root:DATA: {'workers': 10, 'max_color_value': 255.0, 'img_size': 0, 'batch_size': 448, 'crop_size': 224, 'min_scale': 0.087}\n",
      "INFO:root:data: /workspace/dataset/ILSVRC2012-sz/352\n",
      "INFO:root:output_prefix: fast_adv\n",
      "INFO:root:config: configs/cutmix_d1.0/configs_fast_phase3.yml\n",
      "INFO:root:resume: ./trained_models/vanilla_test2_phase2/checkpoint_epoch40.pth.tar\n",
      "INFO:root:evaluate: False\n",
      "INFO:root:pretrained: False\n",
      "INFO:root:restarts: 1\n",
      "INFO:root:output_name: fast_adv\n",
      "INFO:root:**********************************************************************\n",
      "INFO:root:=> creating model 'resnet50'\n",
      "INFO:root:=> loading checkpoint './trained_models/vanilla_test2_phase2/checkpoint_epoch40.pth.tar'\n",
      "INFO:root:=> loaded checkpoint './trained_models/vanilla_test2_phase2/checkpoint_epoch40.pth.tar' (epoch 40)\n"
     ]
    }
   ],
   "source": [
    "# Scale and initialize the parameters\n",
    "best_prec1 = 0\n",
    "\n",
    "# Create output folder\n",
    "if not os.path.isdir(os.path.join('trained_models', configs.output_name)):\n",
    "    os.makedirs(os.path.join('trained_models', configs.output_name))\n",
    "\n",
    "# Log the config details\n",
    "logger.info(pad_str(' ARGUMENTS '))\n",
    "for k, v in configs.items():\n",
    "    print('{}: {}'.format(k, v))\n",
    "logger.info(pad_str(''))\n",
    "\n",
    "# Create the model\n",
    "if configs.pretrained:\n",
    "    print(\"=> using pre-trained model '{}'\".format(configs.TRAIN.arch))\n",
    "    model = models.__dict__[configs.TRAIN.arch](pretrained=True)\n",
    "else:\n",
    "    print(\"=> creating model '{}'\".format(configs.TRAIN.arch))\n",
    "    model = models.__dict__[configs.TRAIN.arch]()\n",
    "\n",
    "def init_dist_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, BasicBlock):\n",
    "            m.bn2.weight = nn.Parameter(torch.zeros_like(m.bn2.weight))\n",
    "        if isinstance(m, Bottleneck):\n",
    "            m.bn3.weight = nn.Parameter(torch.zeros_like(m.bn3.weight))\n",
    "        if isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "\n",
    "init_dist_weights(model)\n",
    "\n",
    "# Wrap the model into DataParallel\n",
    "model.cuda()\n",
    "\n",
    "# reverse mapping\n",
    "param_to_moduleName = {}\n",
    "for m in model.modules():\n",
    "    for p in m.parameters(recurse=False):\n",
    "        param_to_moduleName[p] = str(type(m).__name__)\n",
    "\n",
    "group_decay = [p for p in model.parameters() if 'BatchNorm' not in param_to_moduleName[p]]\n",
    "group_no_decay = [p for p in model.parameters() if 'BatchNorm' in param_to_moduleName[p]]\n",
    "groups = [dict(params=group_decay), dict(params=group_no_decay, weight_decay=0)]\n",
    "optimizer = torch.optim.SGD(groups,\n",
    "                            0,\n",
    "                            momentum=configs.TRAIN.momentum,\n",
    "                            weight_decay=configs.TRAIN.weight_decay)\n",
    "\n",
    "if configs.TRAIN.clean_lam > 0 and not configs.evaluate:\n",
    "    model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\", loss_scale=1024)\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "# Resume if a valid checkpoint path is provided\n",
    "if configs.resume:\n",
    "    if os.path.isfile(configs.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(configs.resume))\n",
    "        checkpoint = torch.load(configs.resume)\n",
    "        configs.TRAIN.start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(configs.resume,\n",
    "                                                            checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(configs.resume))\n",
    "\n",
    "# Initiate data loaders\n",
    "traindir = os.path.join(configs.data, 'train')\n",
    "valdir = os.path.join(configs.data, 'val')\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(configs.DATA.crop_size),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(traindir, train_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=configs.DATA.batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=configs.DATA.workers,\n",
    "                                           pin_memory=True,\n",
    "                                           sampler=None,\n",
    "                                           drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(datasets.ImageFolder(valdir, test_transform),\n",
    "                                         batch_size=configs.DATA.batch_size,\n",
    "                                         shuffle=False,\n",
    "                                         num_workers=configs.DATA.workers,\n",
    "                                         pin_memory=True,\n",
    "                                         drop_last=False)\n",
    "\n",
    "lr_schedule = lambda t: np.interp([t], configs.TRAIN.lr_epochs, configs.TRAIN.lr_values)[0]\n",
    "\n",
    "if configs.TRAIN.mp > 0:\n",
    "    mp = Pool(configs.TRAIN.mp)\n",
    "else:\n",
    "    mp = None\n",
    "    \n",
    "epoch = 40\n",
    "clean_lam=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, optimizer, epoch, lr_schedule, clean_lam=0):\n",
    "    mean = torch.Tensor(np.array(configs.TRAIN.mean)[:, np.newaxis, np.newaxis])\n",
    "    mean = mean.expand(3, configs.DATA.crop_size, configs.DATA.crop_size).cuda()\n",
    "    std = torch.Tensor(np.array(configs.TRAIN.std)[:, np.newaxis, np.newaxis])\n",
    "    std = std.expand(3, configs.DATA.crop_size, configs.DATA.crop_size).cuda()\n",
    "\n",
    "    # Initialize the meters\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "    end = time.time()\n",
    "\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "        input = input.cuda(non_blocking=True)\n",
    "\n",
    "        target = target.cuda(non_blocking=True)\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        # update learning rate\n",
    "        lr = lr_schedule(epoch + (i + 1) / len(train_loader))\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input.sub_(mean).div_(std)\n",
    "        lam = np.random.beta(configs.TRAIN.alpha, configs.TRAIN.alpha)\n",
    "\n",
    "#         #DropMix\n",
    "#         ignore_index = torch.randperm(len(target))[:round(len(target) * configs.TRAIN.ratio)]\n",
    "#         ignore_mask = torch.zeros(len(target)).bool()\n",
    "#         ignore_mask[ignore_index] = True\n",
    "\n",
    "#         target_mixup = target[~ignore_mask]\n",
    "#         target_ignore = target[ignore_mask]\n",
    "#         input_mixup = input[~ignore_mask]\n",
    "#         input_ignore = input[ignore_mask]\n",
    "\n",
    "#         #CutMix\n",
    "#         rand_index = torch.randperm(input_mixup.size()[0]).cuda()\n",
    "#         target_a = torch.cat((target_mixup, target_ignore), 0)\n",
    "#         target_b = torch.cat((target_mixup[rand_index], target_ignore), 0)\n",
    "#         bbx1, bby1, bbx2, bby2 = rand_bbox(input_mixup.size(), lam)\n",
    "#         input_mixup[:, :, bbx1:bbx2, bby1:bby2] = input_mixup[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "#         # adjust lambda to exactly match pixel ratio\n",
    "#         lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input_mixup.size()[-1] * input_mixup.size()[-2]))\n",
    "#         input = torch.cat((input_mixup, input_ignore),0)\n",
    "#         ###\n",
    "# #         pdb.set_trace()\n",
    "\n",
    "#         #Mixup\n",
    "        rand_index = torch.randperm(input.size()[0]).cuda()\n",
    "        target_a = target\n",
    "        target_b = target[rand_index]\n",
    "        input_mixup = input * lam + input[rand_index] * (1. - lam)\n",
    "\n",
    "        input_var = Variable(input_mixup, requires_grad=True)\n",
    "\n",
    "        if clean_lam == 0:\n",
    "            model.eval()\n",
    "\n",
    "        output = model(input_var)\n",
    "        if torch.any(torch.isnan(output)):\n",
    "            pdb.set_trace()\n",
    "#         loss_clean = criterion(output, target)\n",
    "#         #cutmix\n",
    "        loss_clean = criterion(output, target_a) * lam + criterion(output, target_b) * (1. - lam)\n",
    "\n",
    "        if clean_lam > 0:\n",
    "            with amp.scale_loss(loss_clean, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss_clean.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "        # losses.update(loss.item(), input.size(0))\n",
    "        losses.update(loss_clean.item(), input.size(0))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        for name, param in model.named_parameters():\n",
    "            if torch.isnan(param.grad).any():\n",
    "                print(\"nan gradient found\")\n",
    "                pdb.set_trace()\n",
    "        input_pre = input\n",
    "\n",
    "#         if i % configs.TRAIN.print_freq == 0:\n",
    "#             print('Train Epoch: [{0}][{1}/{2}]\\t'\n",
    "#                   'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "#                   'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "#                   'Loss {cls_loss.val:.4f} ({cls_loss.avg:.4f})\\t'\n",
    "#                   'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'\n",
    "#                   'Prec@5 {top5.val:.3f} ({top5.avg:.3f})\\t'\n",
    "#                   'LR {lr:.3f}'.format(epoch,\n",
    "#                                        i,\n",
    "#                                        len(train_loader),\n",
    "#                                        batch_time=batch_time,\n",
    "#                                        data_time=data_time,\n",
    "#                                        top1=top1,\n",
    "#                                        top5=top5,\n",
    "#                                        cls_loss=losses,\n",
    "#                                        lr=lr))\n",
    "#             sys.stdout.flush()\n",
    "    print(' Epoch {epoch}  Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'\n",
    "            .format(epoch=epoch, top1=top1, top5=top5))\n",
    "    return top1.avg, top5.avg, losses.avg, lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mneonsign\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/hi/DropMix/Mixup_imagenet_exp/imagenet_fast/wandb/run-20221023_015422-26gr131q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/neonsign/ImangeNet%20CutMix%20100epoch/runs/26gr131q\" target=\"_blank\">fast_advjupyter</a></strong> to <a href=\"https://wandb.ai/neonsign/ImangeNet%20CutMix%20100epoch\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.init(project=\"ImangeNet CutMix 100epoch\", entity=\"neonsign\", name = configs.output_name + \"jupyter\")\n",
    "wandb.config.update(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-6-34331332d5da>(71)train()\n",
      "-> loss_clean = criterion(output, target_a) * lam + criterion(output, target_b) * (1. - lam)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  input\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.8789,  0.8104,  0.7762,  ...,  0.6049,  0.6049,  0.6049],\n",
      "          [ 0.8961,  0.8276,  0.7248,  ...,  0.6049,  0.6049,  0.6049],\n",
      "          [ 0.8789,  0.7762,  0.6734,  ...,  0.6049,  0.6049,  0.6049],\n",
      "          ...,\n",
      "          [ 1.1015,  1.1015,  1.1015,  ...,  0.8447,  0.8447,  0.8276],\n",
      "          [ 1.1187,  1.1358,  1.1358,  ...,  0.8447,  0.8447,  0.8276],\n",
      "          [ 1.1358,  1.1529,  1.1700,  ...,  0.8447,  0.8447,  0.8276]],\n",
      "\n",
      "         [[ 1.4482,  1.3957,  1.3431,  ...,  1.3431,  1.3431,  1.3431],\n",
      "          [ 1.4482,  1.4132,  1.3081,  ...,  1.3431,  1.3431,  1.3431],\n",
      "          [ 1.4132,  1.3431,  1.2381,  ...,  1.3431,  1.3431,  1.3431],\n",
      "          ...,\n",
      "          [ 1.3782,  1.3782,  1.3957,  ...,  1.2906,  1.2906,  1.2731],\n",
      "          [ 1.3957,  1.4132,  1.4307,  ...,  1.2906,  1.2906,  1.2731],\n",
      "          [ 1.4132,  1.4307,  1.4657,  ...,  1.2906,  1.2906,  1.2731]],\n",
      "\n",
      "         [[ 2.0474,  1.9951,  1.9777,  ...,  2.0300,  2.0300,  2.0300],\n",
      "          [ 2.0300,  1.9951,  1.9080,  ...,  2.0300,  2.0300,  2.0300],\n",
      "          [ 1.9951,  1.9254,  1.8383,  ...,  2.0300,  2.0300,  2.0300],\n",
      "          ...,\n",
      "          [ 1.7163,  1.6988,  1.6814,  ...,  1.8208,  1.8208,  1.8034],\n",
      "          [ 1.7163,  1.7337,  1.7163,  ...,  1.8208,  1.8208,  1.8034],\n",
      "          [ 1.7337,  1.7511,  1.7337,  ...,  1.8208,  1.8208,  1.8034]]],\n",
      "\n",
      "\n",
      "        [[[-0.3541,  0.0398,  0.4337,  ...,  1.0673,  1.2385,  1.4098],\n",
      "          [-0.0629,  0.2111,  0.4679,  ...,  1.2385,  1.4098,  1.5468],\n",
      "          [-0.0972,  0.0398,  0.1597,  ...,  1.5639,  1.6495,  1.7009],\n",
      "          ...,\n",
      "          [-1.1760, -1.3644, -1.4500,  ...,  0.7248,  1.3242,  1.8722],\n",
      "          [-1.1418, -1.3644, -1.4329,  ...,  0.8789,  1.5639,  2.0948],\n",
      "          [-1.0390, -1.4843, -1.6213,  ...,  1.1187,  1.5639,  1.8379]],\n",
      "\n",
      "         [[-0.2325,  0.1702,  0.5728,  ...,  1.1681,  1.3431,  1.5182],\n",
      "          [ 0.0826,  0.3627,  0.6254,  ...,  1.3431,  1.5182,  1.6758],\n",
      "          [ 0.0826,  0.2052,  0.3452,  ...,  1.6758,  1.7633,  1.8158],\n",
      "          ...,\n",
      "          [-0.8978, -1.0728, -1.1604,  ...,  0.8179,  1.4482,  2.0084],\n",
      "          [-0.8277, -1.0553, -1.1253,  ...,  0.9405,  1.6583,  2.2010],\n",
      "          [-0.7227, -1.1779, -1.3179,  ...,  1.1856,  1.6583,  1.9384]],\n",
      "\n",
      "         [[-0.0092,  0.3916,  0.7925,  ...,  1.0539,  1.2282,  1.4025],\n",
      "          [ 0.3742,  0.6356,  0.9145,  ...,  1.2282,  1.3851,  1.5245],\n",
      "          [ 0.3742,  0.5136,  0.6356,  ...,  1.5594,  1.6291,  1.6988],\n",
      "          ...,\n",
      "          [-0.4624, -0.6367, -0.7238,  ...,  0.8099,  1.4374,  1.9951],\n",
      "          [-0.3927, -0.6193, -0.6890,  ...,  0.9494,  1.6640,  2.2043],\n",
      "          [-0.2881, -0.7413, -0.8807,  ...,  1.1934,  1.6640,  1.9428]]],\n",
      "\n",
      "\n",
      "        [[[-0.7137, -0.6965, -0.6965,  ..., -1.8782, -1.8782, -1.8782],\n",
      "          [-0.6794, -0.6623, -0.6623,  ..., -1.8097, -1.8097, -1.8268],\n",
      "          [-0.6794, -0.6794, -0.6623,  ..., -1.7583, -1.7583, -1.7583],\n",
      "          ...,\n",
      "          [ 0.0398,  0.0227,  0.1083,  ..., -1.2959, -1.2959, -1.2959],\n",
      "          [ 0.5193,  0.3481,  0.1083,  ..., -1.3302, -1.3302, -1.3130],\n",
      "          [ 0.4508,  0.6563,  0.7933,  ..., -1.2788, -1.2788, -1.2617]],\n",
      "\n",
      "         [[-1.3004, -1.2829, -1.2829,  ..., -1.9307, -1.9132, -1.8957],\n",
      "          [-1.3179, -1.3004, -1.3004,  ..., -1.9307, -1.9132, -1.9132],\n",
      "          [-1.3179, -1.3179, -1.3004,  ..., -1.8957, -1.8957, -1.8957],\n",
      "          ...,\n",
      "          [-1.0203, -1.0378, -0.9678,  ..., -1.8606, -1.8606, -1.8606],\n",
      "          [-0.4951, -0.6877, -0.9328,  ..., -1.9132, -1.9132, -1.8957],\n",
      "          [-0.5651, -0.3550, -0.2325,  ..., -1.8606, -1.8782, -1.8782]],\n",
      "\n",
      "         [[-1.6999, -1.6824, -1.6824,  ..., -1.6824, -1.6999, -1.7173],\n",
      "          [-1.6824, -1.6650, -1.6650,  ..., -1.6302, -1.6476, -1.6650],\n",
      "          [-1.6824, -1.6824, -1.6650,  ..., -1.6302, -1.6476, -1.6650],\n",
      "          ...,\n",
      "          [-1.6650, -1.7173, -1.6650,  ..., -1.7522, -1.7522, -1.7696],\n",
      "          [-1.1596, -1.3861, -1.6476,  ..., -1.8044, -1.8044, -1.7870],\n",
      "          [-1.2293, -1.0376, -0.9504,  ..., -1.7522, -1.7522, -1.7522]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2796,  0.3309,  0.2796,  ...,  0.9303,  0.8961,  0.9132],\n",
      "          [ 0.2453,  0.2111,  0.1426,  ...,  0.9988,  0.8789,  0.8104],\n",
      "          [ 0.3823,  0.2624,  0.2453,  ...,  1.0502,  0.9303,  0.8789],\n",
      "          ...,\n",
      "          [-0.0287,  0.1939,  0.2111,  ..., -0.2171, -0.2856, -0.1486],\n",
      "          [ 0.1939,  0.3652,  0.4337,  ...,  0.0741,  0.0741,  0.0227],\n",
      "          [ 0.2111,  0.6049,  0.6563,  ...,  0.0741,  0.1254,  0.1597]],\n",
      "\n",
      "         [[ 0.3627,  0.3803,  0.3452,  ...,  1.0105,  0.9755,  0.9930],\n",
      "          [ 0.3277,  0.2577,  0.2052,  ...,  1.1155,  0.9930,  0.9230],\n",
      "          [ 0.4678,  0.3102,  0.3277,  ...,  1.1681,  1.0455,  0.9930],\n",
      "          ...,\n",
      "          [ 0.3102,  0.5203,  0.5553,  ...,  0.1527,  0.0826,  0.2227],\n",
      "          [ 0.5378,  0.7129,  0.7829,  ...,  0.5028,  0.5203,  0.4853],\n",
      "          [ 0.5378,  0.9405,  1.0105,  ...,  0.4853,  0.5553,  0.6078]],\n",
      "\n",
      "         [[ 0.0256,  0.0605, -0.0267,  ...,  0.5834,  0.5485,  0.5659],\n",
      "          [ 0.0082, -0.0441, -0.1312,  ...,  0.6705,  0.5485,  0.4788],\n",
      "          [ 0.1128,  0.0082, -0.0092,  ...,  0.7228,  0.6008,  0.5485],\n",
      "          ...,\n",
      "          [-0.1835,  0.0256,  0.0431,  ..., -0.3055, -0.3753, -0.2532],\n",
      "          [ 0.0605,  0.2348,  0.3045,  ..., -0.0092,  0.0082, -0.0267],\n",
      "          [ 0.0605,  0.4614,  0.5311,  ..., -0.0267,  0.0431,  0.0779]]],\n",
      "\n",
      "\n",
      "        [[[-0.1143,  0.0912,  0.1597,  ...,  0.9817,  0.9132,  0.7933],\n",
      "          [-0.2684,  0.0398,  0.1254,  ...,  0.9988,  0.8961,  0.8104],\n",
      "          [-0.4911, -0.0629,  0.0569,  ...,  0.9817,  0.9303,  0.8789],\n",
      "          ...,\n",
      "          [-0.4568, -0.6623, -0.8507,  ..., -0.6109, -0.6623, -0.7479],\n",
      "          [-0.5082, -0.6109, -0.7993,  ..., -0.5424, -0.6452, -0.7650],\n",
      "          [-0.5082, -0.6452, -0.8164,  ..., -0.5082, -0.5767, -0.6452]],\n",
      "\n",
      "         [[ 0.1877,  0.3978,  0.4853,  ...,  1.2556,  1.2556,  1.1506],\n",
      "          [-0.0049,  0.3277,  0.4328,  ...,  1.2906,  1.2731,  1.2031],\n",
      "          [-0.1800,  0.2577,  0.3803,  ...,  1.2556,  1.2381,  1.1506],\n",
      "          ...,\n",
      "          [-0.1450, -0.3725, -0.5826,  ..., -0.5126, -0.5476, -0.6352],\n",
      "          [-0.1800, -0.3200, -0.5301,  ..., -0.4426, -0.5301, -0.6527],\n",
      "          [-0.1975, -0.3550, -0.5301,  ..., -0.4076, -0.4601, -0.5301]],\n",
      "\n",
      "         [[ 0.3916,  0.5834,  0.6356,  ...,  1.8034,  1.6988,  1.5420],\n",
      "          [ 0.2522,  0.5485,  0.6356,  ...,  1.8557,  1.7163,  1.6117],\n",
      "          [ 0.0256,  0.4439,  0.5659,  ...,  1.8557,  1.7511,  1.6640],\n",
      "          ...,\n",
      "          [-0.0441, -0.2532, -0.4624,  ..., -0.1835, -0.1835, -0.2707],\n",
      "          [-0.1138, -0.2358, -0.4275,  ..., -0.0964, -0.1487, -0.2532],\n",
      "          [-0.1661, -0.2881, -0.4624,  ..., -0.0441, -0.0790, -0.1312]]],\n",
      "\n",
      "\n",
      "        [[[-0.1486,  0.9474,  1.5297,  ..., -0.9877, -0.9020, -0.2513],\n",
      "          [ 0.2796,  0.8447,  1.3242,  ...,  0.0227,  0.1939,  0.4337],\n",
      "          [ 0.9303,  0.8789,  1.1872,  ...,  0.8447,  1.0844,  0.9474],\n",
      "          ...,\n",
      "          [-1.4329, -1.4158, -1.4158,  ...,  0.1939,  1.0673,  1.8379],\n",
      "          [-1.4329, -1.4158, -1.4158,  ..., -0.3198,  0.3652,  1.4612],\n",
      "          [-1.4329, -1.4329, -1.4329,  ..., -0.7479, -0.3883,  0.7762]],\n",
      "\n",
      "         [[-0.0224,  1.0980,  1.6933,  ..., -0.5301, -0.4076,  0.2577],\n",
      "          [ 0.4153,  1.0105,  1.4832,  ...,  0.5028,  0.7129,  0.9580],\n",
      "          [ 1.0805,  1.0455,  1.3431,  ...,  1.3256,  1.6232,  1.4832],\n",
      "          ...,\n",
      "          [-1.3354, -1.3179, -1.3179,  ...,  0.2927,  1.2031,  1.9734],\n",
      "          [-1.3354, -1.3179, -1.3179,  ..., -0.2325,  0.4853,  1.6057],\n",
      "          [-1.3354, -1.3354, -1.3354,  ..., -0.6527, -0.2850,  0.9055]],\n",
      "\n",
      "         [[ 0.3393,  1.4374,  1.9951,  ..., -1.4733, -1.4559, -0.8284],\n",
      "          [ 0.7751,  1.3328,  1.7860,  ..., -0.4450, -0.3404, -0.1312],\n",
      "          [ 1.4374,  1.3677,  1.6465,  ...,  0.4439,  0.6008,  0.4265],\n",
      "          ...,\n",
      "          [-0.6715, -0.6541, -0.6367,  ...,  1.0714,  1.9254,  2.6051],\n",
      "          [-0.6541, -0.6367, -0.6193,  ...,  0.5485,  1.2108,  2.2566],\n",
      "          [-0.6541, -0.6541, -0.6367,  ...,  0.1128,  0.4962,  1.6814]]]],\n",
      "       device='cuda:0')\n",
      "--KeyboardInterrupt--\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9af52bccd83d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# train for one epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtprec1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtprec5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_schedule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclean_lam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# evaluate on validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-34331332d5da>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, optimizer, epoch, lr_schedule, clean_lam)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#         loss_clean = criterion(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#         #cutmix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mloss_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclean_lam\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-34331332d5da>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, optimizer, epoch, lr_schedule, clean_lam)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#         loss_clean = criterion(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m#         #cutmix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mloss_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclean_lam\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "wandb.watch(model)\n",
    "for epoch in range(configs.TRAIN.start_epoch, configs.TRAIN.epochs):\n",
    "    # train for one epoch\n",
    "    tprec1, tprec5, tloss, lr = train(train_loader, model, optimizer, epoch, lr_schedule, configs.TRAIN.clean_lam)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    prec1, prec5, loss = validate(val_loader, model, criterion, configs, logger)\n",
    "\n",
    "    wandb.log({\n",
    "        \"Loss/train\": tloss, \n",
    "        \"Loss/validation\": loss, \n",
    "        \"prec1/train\": tprec1, \n",
    "        \"prec1/validation\": prec1, \n",
    "        \"prec5/train\": tprec5, \n",
    "        \"prec5/validation\": prec5, \n",
    "        \"Learning Rate\": lr})\n",
    "    # remember best prec@1 and save checkpoint\n",
    "    is_best = prec1 > best_prec1\n",
    "    best_prec1 = max(prec1, best_prec1)\n",
    "    if is_best:\n",
    "        wandb.run.summary[\"best_prec1\"] = best_prec1\n",
    "    save_checkpoint(\n",
    "        {\n",
    "            'epoch': epoch + 1,\n",
    "            'arch': configs.TRAIN.arch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "        }, is_best, os.path.join('trained_models', f'{configs.output_name}'), epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-9-a4de806e85a9>(70)<module>()\n",
      "-> loss_clean = criterion(output, target_a) * lam + criterion(output, target_b) * (1. - lam)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a4de806e85a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m#         loss_clean = criterion(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#         #cutmix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mloss_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclean_lam\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-a4de806e85a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;31m#         loss_clean = criterion(output, target)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;31m#         #cutmix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mloss_clean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_a\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlam\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_b\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mclean_lam\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mean = torch.Tensor(np.array(configs.TRAIN.mean)[:, np.newaxis, np.newaxis])\n",
    "mean = mean.expand(3, configs.DATA.crop_size, configs.DATA.crop_size).cuda()\n",
    "std = torch.Tensor(np.array(configs.TRAIN.std)[:, np.newaxis, np.newaxis])\n",
    "std = std.expand(3, configs.DATA.crop_size, configs.DATA.crop_size).cuda()\n",
    "\n",
    "# Initialize the meters\n",
    "batch_time = AverageMeter()\n",
    "data_time = AverageMeter()\n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "# switch to train mode\n",
    "model.train()\n",
    "end = time.time()\n",
    "\n",
    "for i, (input, target) in enumerate(train_loader):\n",
    "    input = input.cuda(non_blocking=True)\n",
    "\n",
    "    target = target.cuda(non_blocking=True)\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    # update learning rate\n",
    "    lr = lr_schedule(epoch + (i + 1) / len(train_loader))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    input.sub_(mean).div_(std)\n",
    "    lam = np.random.beta(configs.TRAIN.alpha, configs.TRAIN.alpha)\n",
    "\n",
    "#         #DropMix\n",
    "#         ignore_index = torch.randperm(len(target))[:round(len(target) * configs.TRAIN.ratio)]\n",
    "#         ignore_mask = torch.zeros(len(target)).bool()\n",
    "#         ignore_mask[ignore_index] = True\n",
    "\n",
    "#         target_mixup = target[~ignore_mask]\n",
    "#         target_ignore = target[ignore_mask]\n",
    "#         input_mixup = input[~ignore_mask]\n",
    "#         input_ignore = input[ignore_mask]\n",
    "\n",
    "#         #CutMix\n",
    "#         rand_index = torch.randperm(input_mixup.size()[0]).cuda()\n",
    "#         target_a = torch.cat((target_mixup, target_ignore), 0)\n",
    "#         target_b = torch.cat((target_mixup[rand_index], target_ignore), 0)\n",
    "#         bbx1, bby1, bbx2, bby2 = rand_bbox(input_mixup.size(), lam)\n",
    "#         input_mixup[:, :, bbx1:bbx2, bby1:bby2] = input_mixup[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "#         # adjust lambda to exactly match pixel ratio\n",
    "#         lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input_mixup.size()[-1] * input_mixup.size()[-2]))\n",
    "#         input = torch.cat((input_mixup, input_ignore),0)\n",
    "#         ###\n",
    "# #         pdb.set_trace()\n",
    "\n",
    "#         #Mixup\n",
    "    rand_index = torch.randperm(input.size()[0]).cuda()\n",
    "    target_a = target\n",
    "    target_b = target[rand_index]\n",
    "    input_mixup = input * lam + input[rand_index] * (1. - lam)\n",
    "\n",
    "    input_var = Variable(input_mixup, requires_grad=True)\n",
    "\n",
    "    if clean_lam == 0:\n",
    "        model.eval()\n",
    "\n",
    "    output = model(input_var)\n",
    "    if torch.any(torch.isnan(output)):\n",
    "        pdb.set_trace()\n",
    "#         loss_clean = criterion(output, target)\n",
    "#         #cutmix\n",
    "    loss_clean = criterion(output, target_a) * lam + criterion(output, target_b) * (1. - lam)\n",
    "\n",
    "    if clean_lam > 0:\n",
    "        with amp.scale_loss(loss_clean, optimizer) as scaled_loss:\n",
    "            scaled_loss.backward()\n",
    "    else:\n",
    "        loss_clean.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "    # losses.update(loss.item(), input.size(0))\n",
    "    losses.update(loss_clean.item(), input.size(0))\n",
    "    top1.update(prec1[0], input.size(0))\n",
    "    top5.update(prec5[0], input.size(0))\n",
    "\n",
    "    # measure elapsed time\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()\n",
    "    for name, param in model.named_parameters():\n",
    "        if torch.isnan(param.grad).any():\n",
    "            print(\"nan gradient found\")\n",
    "            pdb.set_trace()\n",
    "    input_pre = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False, device='cuda:0')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(input).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([448, 3, 224, 224])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(model(torch.ones(448,3,224,224))).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.6.0a0+9907a3e'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-4-fb5d33d94222>(66)<module>()\n",
      "-> if clean_lam > 0:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** NameError: name 'nan' is not defined\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  output\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        ...,\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan],\n",
      "        [nan, nan, nan,  ..., nan, nan, nan]], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "(Pdb)  exit\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-fb5d33d94222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mclean_lam\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-fb5d33d94222>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mclean_lam\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_clean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mscaled_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mean = torch.Tensor(np.array(configs.TRAIN.mean)[:, np.newaxis, np.newaxis])\n",
    "mean = mean.expand(3, configs.DATA.crop_size, configs.DATA.crop_size).cuda()\n",
    "std = torch.Tensor(np.array(configs.TRAIN.std)[:, np.newaxis, np.newaxis])\n",
    "std = std.expand(3, configs.DATA.crop_size, configs.DATA.crop_size).cuda()\n",
    "\n",
    "# Initialize the meters\n",
    "batch_time = AverageMeter()\n",
    "data_time = AverageMeter()\n",
    "losses = AverageMeter()\n",
    "top1 = AverageMeter()\n",
    "top5 = AverageMeter()\n",
    "# switch to train mode\n",
    "model.train()\n",
    "end = time.time()\n",
    "\n",
    "for i, (input, target) in enumerate(train_loader):\n",
    "    input = input.cuda(non_blocking=True)\n",
    "\n",
    "    target = target.cuda(non_blocking=True)\n",
    "    data_time.update(time.time() - end)\n",
    "\n",
    "    # update learning rate\n",
    "    lr = lr_schedule(epoch + (i + 1) / len(train_loader))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    input.sub_(mean).div_(std)\n",
    "#         lam = np.random.beta(configs.TRAIN.alpha, configs.TRAIN.alpha)\n",
    "\n",
    "#         #DropMix\n",
    "#         ignore_index = torch.randperm(len(target))[:round(len(target) * configs.TRAIN.ratio)]\n",
    "#         ignore_mask = torch.zeros(len(target)).bool()\n",
    "#         ignore_mask[ignore_index] = True\n",
    "\n",
    "#         target_mixup = target[~ignore_mask]\n",
    "#         target_ignore = target[ignore_mask]\n",
    "#         input_mixup = input[~ignore_mask]\n",
    "#         input_ignore = input[ignore_mask]\n",
    "\n",
    "#         #CutMix\n",
    "#         rand_index = torch.randperm(input_mixup.size()[0]).cuda()\n",
    "#         target_a = torch.cat((target_mixup, target_ignore), 0)\n",
    "#         target_b = torch.cat((target_mixup[rand_index], target_ignore), 0)\n",
    "#         bbx1, bby1, bbx2, bby2 = rand_bbox(input_mixup.size(), lam)\n",
    "#         input_mixup[:, :, bbx1:bbx2, bby1:bby2] = input_mixup[rand_index, :, bbx1:bbx2, bby1:bby2]\n",
    "#         # adjust lambda to exactly match pixel ratio\n",
    "#         lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (input_mixup.size()[-1] * input_mixup.size()[-2]))\n",
    "#         input = torch.cat((input_mixup, input_ignore),0)\n",
    "#         ###\n",
    "# #         pdb.set_trace()\n",
    "\n",
    "    input_var = Variable(input, requires_grad=True)\n",
    "\n",
    "    if clean_lam == 0:\n",
    "        model.eval()\n",
    "\n",
    "    output = model(input_var)\n",
    "    loss_clean = criterion(output, target)\n",
    "#         #cutmix\n",
    "#         loss_clean = criterion(output, target_a) * lam + criterion(output, target_b) * (1. - lam)\n",
    "    if torch.isnan(loss_clean):\n",
    "        pdb.set_trace()\n",
    "\n",
    "#     if clean_lam > 0:\n",
    "#         with amp.scale_loss(loss_clean, optimizer) as scaled_loss:\n",
    "#             scaled_loss.backward()\n",
    "#     else:\n",
    "#         loss_clean.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "    # losses.update(loss.item(), input.size(0))\n",
    "    losses.update(loss_clean.item(), input.size(0))\n",
    "    top1.update(prec1[0], input.size(0))\n",
    "    top5.update(prec5[0], input.size(0))\n",
    "\n",
    "    # measure elapsed time\n",
    "    batch_time.update(time.time() - end)\n",
    "    end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Final Prec@1 69.372 Prec@5 89.286\n"
     ]
    }
   ],
   "source": [
    "prec1, prec5, loss = validate(val_loader, model, criterion, configs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec1, prec5, loss = validate(val_loader, model, criterion, configs, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
