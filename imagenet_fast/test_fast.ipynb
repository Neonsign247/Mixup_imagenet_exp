{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_paths\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from validation import validate\n",
    "#import torchvision.models as models\n",
    "import models\n",
    "from models.imagenet_resnet import BasicBlock, Bottleneck\n",
    "from multiprocessing import Pool\n",
    "#from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "import pdb\n",
    "import wandb\n",
    "\n",
    "from apex import amp\n",
    "import copy\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_width = 192\n",
    "\n",
    "TOTAL_BAR_LENGTH = 65.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet50'\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "arch = 'resnet50'\n",
    "print(\"=> creating model '{}'\".format(arch))\n",
    "model = models.__dict__[arch]()\n",
    "numberofclass = 1000\n",
    "\n",
    "def init_dist_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, BasicBlock):\n",
    "            m.bn2.weight = nn.Parameter(torch.zeros_like(m.bn2.weight))\n",
    "        if isinstance(m, Bottleneck):\n",
    "            m.bn3.weight = nn.Parameter(torch.zeros_like(m.bn3.weight))\n",
    "        if isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "\n",
    "init_dist_weights(model)\n",
    "# Wrap the model into DataParallel\n",
    "model.cuda()\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "valdir = os.path.join('/workspace/dataset/ILSVRC2012/val')\n",
    "valdir = os.path.join('/workspace/dataset/ILSVRC2012-sz/352/val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=512, shuffle=False,\n",
    "    num_workers=10, pin_memory=True)\n",
    "\n",
    "\n",
    "# # Initiate data loaders\n",
    "# data = '/workspace/dataset/ILSVRC2012-sz/352'\n",
    "# crop_size = 224\n",
    "# min_scale = 0.087\n",
    "# batch_size = 448\n",
    "# workers = 10\n",
    "# traindir = os.path.join(data, 'train')\n",
    "# valdir = os.path.join(data, 'val')\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(crop_size, scale=(min_scale, 1.0)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# train_dataset = datasets.ImageFolder(traindir, train_transform)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "#                                            batch_size=batch_size,\n",
    "#                                            shuffle=True,\n",
    "#                                            num_workers=workers,\n",
    "#                                            pin_memory=True,\n",
    "#                                            sampler=None,\n",
    "#                                            drop_last=True)\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(datasets.ImageFolder(valdir, test_transform),\n",
    "#                                          batch_size=batch_size,\n",
    "#                                          shuffle=False,\n",
    "#                                          num_workers=workers,\n",
    "#                                          pin_memory=True,\n",
    "#                                          drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'ResNet50_Baseline_23.68'\n",
      "=> loaded checkpoint 'ResNet50_Baseline_23.68'\n",
      "DataParallel(\n",
      "  (module): ResNet(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)\n",
      "    (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "the number of model parameters: 25557032\n"
     ]
    }
   ],
   "source": [
    "resume = ''\n",
    "if os.path.isfile(resume):\n",
    "    print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "    checkpoint = torch.load(resume)\n",
    "    start_epoch = checkpoint['epoch']\n",
    "    best_prec1 = checkpoint['best_prec1']\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    print(\"=> loaded checkpoint '{}' (epoch {})\".format(resume,\n",
    "                                                        checkpoint['epoch']))\n",
    "else:\n",
    "    print(\"=> no checkpoint found at '{}'\".format(resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'trained_models/cutmix_d0.9_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.9_phase3/model_best.pth.tar' (epoch 93)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.2439956665039\n",
      " [================================================================>]  Step: 183ms | Tot: 28s972ms | eval                                                                                       98/98 6/98                                                               90/98 \n",
      " Final Prec@1 76.256 Prec@5 92.984\n"
     ]
    }
   ],
   "source": [
    "for exp in ['cutmix_d0.9_phase3']:\n",
    "#             'cutmix_phase3',\n",
    "#             'vanilla_phase3',\n",
    "#             'cutmix_d0.0_phase3',\n",
    "#             'cutmix_d0.1_phase3',\n",
    "#             'cutmix_d0.3_phase3',\n",
    "#             'cutmix_d0.5_phase3',\n",
    "#             'cutmix_d0.6_phase3',\n",
    "#             'cutmix_d0.7_phase3',\n",
    "#             'cutmix_d0.8_phase3',\n",
    "#             'cutmix_d1.0_phase3']:\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    expname = exp\n",
    "#     resume = '../../Mixup_imagenet_exp_old/imagenet_fast/trained_models/' + expname + '/model_best.pth.tar'\n",
    "    resume = 'trained_models/' + expname + '/model_best.pth.tar'\n",
    "    if os.path.isfile(resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "        checkpoint = torch.load(resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(resume,\n",
    "                                                            checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "\n",
    "    print('the number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "    print('best prec1: {}'.format(best_prec1))\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    correct_classes = np.zeros(numberofclass, dtype=int)\n",
    "    number_classes = np.zeros(numberofclass, dtype=int)\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda()\n",
    "\n",
    "        output = model(input)\n",
    "        \n",
    "        prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        output = output.data\n",
    "        topk=(1,)\n",
    "\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        for c, n in zip(correct.reshape(-1).int(), target):\n",
    "            correct_classes[n] += c\n",
    "            number_classes[n] += 1\n",
    "\n",
    "        progress_bar(i, len(val_loader), 'eval')\n",
    "    print(' Final Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
    "    np.savetxt('recall/' + expname + '_val.csv', np.transpose(np.stack((correct_classes, number_classes, correct_classes/number_classes))), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'trained_models/cutmix_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_phase3/model_best.pth.tar' (epoch 90)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 77.09400177001953\n",
      " [================================================================>]  Step: 123ms | Tot: 54s792ms | eval                                                                                       98/98 .........................................]  Step: 197ms | Tot: 17s468ms | eval                                                                                       6/98 30/98                                                                38/98 .............................]  Step: 200ms | Tot: 34s413ms | eval                                                                                       40/98 59/98 61/98 62/98                    63/9 72/9 73/98 \n",
      " Final Prec@1 76.516 Prec@5 93.206\n",
      "=> loading checkpoint 'trained_models/vanilla_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/vanilla_phase3/model_best.pth.tar' (epoch 85)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 75.66999816894531\n",
      " [================================================================>]  Step: 115ms | Tot: 24s568ms | eval                                                                                       98/98 56/98 ........]  Step: 198ms | Tot: 15s270ms | eval                                                                                       59/98 67/9 86/98 \n",
      " Final Prec@1 75.118 Prec@5 92.412\n",
      "=> loading checkpoint 'trained_models/cutmix_d0.0_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.0_phase3/model_best.pth.tar' (epoch 97)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 77.18399810791016\n",
      " [================================================================>]  Step: 149ms | Tot: 23s961ms | eval                                                                                       98/98                                                   8/9 9/9 38/98 73/98           74/98 \n",
      " Final Prec@1 76.150 Prec@5 93.264\n",
      "=> loading checkpoint 'trained_models/cutmix_d0.1_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.1_phase3/model_best.pth.tar' (epoch 100)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 77.3499984741211\n",
      " [================================================================>]  Step: 131ms | Tot: 23s559ms | eval                                                                                       98/98 ...........................]  Step: 196ms | Tot: 5s937ms | eval                                                                                        25/98           39/9 56/98                                                                  70/98 \n",
      " Final Prec@1 76.526 Prec@5 93.368\n",
      "=> loading checkpoint 'trained_models/cutmix_d0.3_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.3_phase3/model_best.pth.tar' (epoch 95)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 77.01200103759766\n",
      " [================================================================>]  Step: 363ms | Tot: 24s208ms | eval                                                                                       98/98 ...............................]  Step: 197ms | Tot: 10s679ms | eval                                                                                       47/98 ]  Step: 264ms | Tot: 11s338ms | eval                                                                                       50/98 \n",
      " Final Prec@1 76.356 Prec@5 93.288\n",
      "=> loading checkpoint 'trained_models/cutmix_d0.5_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.5_phase3/model_best.pth.tar' (epoch 96)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.72599792480469\n",
      " [================================================================>]  Step: 114ms | Tot: 23s424ms | eval                                                                                       98/98 98 ...................................................]  Step: 196ms | Tot: 3s334ms | eval                                                                                        16/98 33/98 93/98 \n",
      " Final Prec@1 76.134 Prec@5 93.074\n",
      "=> loading checkpoint 'trained_models/cutmix_d0.6_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.6_phase3/model_best.pth.tar' (epoch 99)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.87845611572266\n",
      " [================================================================>]  Step: 117ms | Tot: 23s730ms | eval                                                                                       98/98 ..........]  Step: 193ms | Tot: 2s794ms | eval                                                                                        12/98  45/98 \n",
      " Final Prec@1 76.468 Prec@5 93.276\n",
      "=> loading checkpoint 'trained_models/cutmix_d0.7_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.7_phase3/model_best.pth.tar' (epoch 99)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.66199493408203\n",
      " [================================================================>]  Step: 143ms | Tot: 23s529ms | eval                                                                                       98/98    18/98 ====================>............................]  Step: 200ms | Tot: 13s705ms | eval                                                                                       56/9 61/98 66/9 77/98 =========>.]  Step: 196ms | Tot: 23s91ms | eval                                                                                        96/98 \n",
      " Final Prec@1 75.954 Prec@5 92.934\n",
      "=> loading checkpoint 'trained_models/cutmix_d0.8_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.8_phase3/model_best.pth.tar' (epoch 98)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.70646667480469\n",
      " [================================================================>]  Step: 124ms | Tot: 23s946ms | eval                                                                                       98/98                                     13/98 ..............................]  Step: 203ms | Tot: 3s673ms | eval                                                                                        14/98 46/98 54/98 \n",
      " Final Prec@1 76.144 Prec@5 93.026\n",
      "=> loading checkpoint 'trained_models/cutmix_d1.0_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d1.0_phase3/model_best.pth.tar' (epoch 92)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 75.80400085449219\n",
      " [================================================================>]  Step: 112ms | Tot: 24s214ms | eval                                                                                       98/98 ..............]  Step: 196ms | Tot: 377ms | eval                                                                                          3/98 4/98 ................................]  Step: 248ms | Tot: 4s109ms | eval                                                                                        20/9 47/98 ..................]  Step: 216ms | Tot: 11s399ms | eval                                                                                       48/9 66/98 \n",
      " Final Prec@1 75.324 Prec@5 92.504\n"
     ]
    }
   ],
   "source": [
    "for exp in ['cutmix_phase3',\n",
    "            'vanilla_phase3',\n",
    "            'cutmix_d0.0_phase3',\n",
    "            'cutmix_d0.1_phase3',\n",
    "            'cutmix_d0.3_phase3',\n",
    "            'cutmix_d0.5_phase3',\n",
    "            'cutmix_d0.6_phase3',\n",
    "            'cutmix_d0.7_phase3',\n",
    "            'cutmix_d0.8_phase3',\n",
    "            'cutmix_d1.0_phase3']:\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    expname = exp\n",
    "#     resume = '../../Mixup_imagenet_exp_old/imagenet_fast/trained_models/' + expname + '/model_best.pth.tar'\n",
    "    resume = 'trained_models/' + expname + '/model_best.pth.tar'\n",
    "    if os.path.isfile(resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "        checkpoint = torch.load(resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(resume,\n",
    "                                                            checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "\n",
    "    print('the number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "    print('best prec1: {}'.format(best_prec1))\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    correct_classes = np.zeros(numberofclass, dtype=int)\n",
    "    number_classes = np.zeros(numberofclass, dtype=int)\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda()\n",
    "\n",
    "        output = model(input)\n",
    "        \n",
    "        prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        output = output.data\n",
    "        topk=(1,)\n",
    "\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        for c, n in zip(correct.reshape(-1).int(), target):\n",
    "            correct_classes[n] += c\n",
    "            number_classes[n] += 1\n",
    "\n",
    "        progress_bar(i, len(val_loader), 'eval')\n",
    "    print(' Final Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
    "    np.savetxt('recall/' + expname + '_val.csv', np.transpose(np.stack((correct_classes, number_classes, correct_classes/number_classes))), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'trained_models/cutmix_d0.0_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.0_phase1/model_best.pth.tar' (epoch 100)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 77.19400024414062\n",
      " [================================================================>]  Step: 120ms | Tot: 36s842ms | eval                                                                                       98/98 98 9/9 18/98 .....]  Step: 193ms | Tot: 18s27ms | eval                                                                                        39/98                                  40/9 62/98                                                                       69/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.1_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.1_phase1/model_best.pth.tar' (epoch 94)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.9964599609375\n",
      " [================================================================>]  Step: 117ms | Tot: 23s387ms | eval                                                                                       98/98 37/98                                                      55/98 ====================>.......................]  Step: 204ms | Tot: 15s568ms | eval                                                                                       64/98 ================================>.............]  Step: 198ms | Tot: 18s804ms | eval                                                                                       78/98 79/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.2_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.2_phase1/model_best.pth.tar' (epoch 100)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 77.11245727539062\n",
      " [================================================================>]  Step: 110ms | Tot: 24s463ms | eval                                                                                       98/98              38/98 ====================================================>.....]  Step: 197ms | Tot: 23s418ms | eval                                                                                       91/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.3_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.3_phase1/model_best.pth.tar' (epoch 89)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.91600036621094\n",
      " [================================================================>]  Step: 115ms | Tot: 33s520ms | eval                                                                                       98/98 98                     12/9 39/98 77/98 =================================>.....]  Step: 195ms | Tot: 32s215ms | eval                                                                                       90/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.4_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.4_phase1/model_best.pth.tar' (epoch 96)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.74446105957031\n",
      " [================================================================>]  Step: 179ms | Tot: 24s82ms | eval                                                                                        98/98 ...........................................................]  Step: 198ms | Tot: 1s80ms | eval                                                                                         7/98                                                       16/98                                                                                      58/98 =============>.................]  Step: 195ms | Tot: 18s222ms | eval                                                                                       73/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.5_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.5_phase1/model_best.pth.tar' (epoch 96)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.1240005493164\n",
      " [================================================================>]  Step: 119ms | Tot: 23s643ms | eval                                                                                       98/98                                               8/98 ]  Step: 199ms | Tot: 3s625ms | eval                                                                                        19/98 ...............................]  Step: 232ms | Tot: 5s887ms | eval                                                                                        26/98 ...................]  Step: 199ms | Tot: 14s563ms | eval                                                                                       59/98                                                               65/98 ...]  Step: 197ms | Tot: 16s245ms | eval                                                                                       67/98 ==============================>...............]  Step: 254ms | Tot: 18s415ms | eval                                                                                       76/9 84/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.6_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.6_phase1/model_best.pth.tar' (epoch 98)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 75.86199951171875\n",
      " [================================================================>]  Step: 123ms | Tot: 23s443ms | eval                                                                                       98/98 /98                                                                            36/9 45/98                                                                                      50/98                                     69 70/98 90/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.7_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.7_phase1/model_best.pth.tar' (epoch 99)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 75.40599822998047\n",
      " [================================================================>]  Step: 119ms | Tot: 24s215ms | eval                                                                                       98/98 42/9 56/98  57/9 64/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.8_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.8_phase1/model_best.pth.tar' (epoch 66)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 74.82250213623047\n",
      " [================================================================>]  Step: 111ms | Tot: 22s836ms | eval                                                                                       98/98                                                                     17/9 55/98                                                                                  90/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.9_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.9_phase1/model_best.pth.tar' (epoch 65)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 74.30400085449219\n",
      " [================================================================>]  Step: 119ms | Tot: 22s807ms | eval                                                                                       98/98 ................]  Step: 240ms | Tot: 3s201ms | eval                                                                                        14/9 22/98 ..........................]  Step: 198ms | Tot: 8s135ms | eval                                                                                        33/98 ======>.......................................]  Step: 200ms | Tot: 9s410ms | eval                                                                                        39/98 ====>......................................]  Step: 201ms | Tot: 9s770ms | eval                                                                                        41/98                                 47/98                                                                83/98 ======================================>..]  Step: 200ms | Tot: 22s321ms | eval                                                                                       95/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d1.0_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d1.0_phase1/model_best.pth.tar' (epoch 67)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 73.38652801513672\n",
      " [================================================================>]  Step: 110ms | Tot: 22s790ms | eval                                                                                       98/98 /9 22/98                                                                 52/98                                       80/98 \n"
     ]
    }
   ],
   "source": [
    "for exp in range(0,11):\n",
    "    expname = 'cutmix_d' + str(exp/10)\n",
    "    resume = 'trained_models/' + expname + '_phase1/model_best.pth.tar'\n",
    "    if os.path.isfile(resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "        checkpoint = torch.load(resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(resume,\n",
    "                                                            checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "\n",
    "    print('the number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "    print('best prec1: {}'.format(best_prec1))\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    correct_classes = np.zeros(numberofclass, dtype=int)\n",
    "    number_classes = np.zeros(numberofclass, dtype=int)\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda()\n",
    "\n",
    "        output = model(input)\n",
    "        output = output.data\n",
    "        topk=(1,)\n",
    "\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        for c, n in zip(correct.reshape(-1).int(), target):\n",
    "            correct_classes[n] += c\n",
    "            number_classes[n] += 1\n",
    "\n",
    "        progress_bar(i, len(val_loader), 'eval')\n",
    "    np.savetxt('recall/' + expname + '_val.csv', np.transpose(np.stack((correct_classes, number_classes, correct_classes/number_classes))), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 1000]), torch.Size([256]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numberofclass = 1000\n",
    "correct_classes = torch.empty(numberofclass, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8177e+31)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classes[500][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "degraded_cls_list = torch.tensor([266, 193, 250, 660, 764, 620, 380, 409, 676, 887, 928, 975, 171, 311, 377, 857, 101, 46, 543, 559, 579, 803, 813, 885, 32, 748, 63, 142, 161, 186, 402, 629, 868, 878, 908, 233, 249, 304, 489, 506, 600, 696, 812, 814, 911, 923, 26, 77, 134, 202, 210, 243, 328, 382, 385, 473, 486, 522, 667, 711, 795, 797, 830, 902, 950, 68, 282, 415, 664, 838, 841, 860, 978, 999, 50, 184, 197, 383, 412, 457, 500, 507, 650, 693, 759, 778, 825, 844, 931, 939, 43, 81, 140, 165, 252, 297, 331, 345, 367, 379, 468, 546, 645, 726, 754, 756, 859, 864, 901, 972, 983, 4, 25, 115, 126, 152, 163, 204, 258, 259, 322, 442, 487, 538, 585, 589, 593, 596, 606, 617, 622, 710, 852, 914, 958, 990, 60, 73, 493, 567, 657, 848, 240, 44, 45, 71, 94, 158, 159, 178, 188, 199, 217, 288, 337, 349, 438, 466, 535, 578, 648, 678, 694, 735, 780, 786, 808, 880, 884, 980, 9, 90, 139, 182, 223, 230, 287, 295, 313, 356, 375, 448, 513, 708, 736, 740, 793, 799, 826, 856, 867, 889, 917, 918, 943, 7, 18, 23, 24, 34, 69, 74, 75, 78, 80, 82, 89, 92, 96, 97, 103, 116, 122, 131, 144, 157, 168, 174, 185, 194, 195, 213, 231, 234, 248, 261, 262, 272, 273, 274, 279, 284, 302, 307, 317, 338, 342, 343, 352, 354, 355, 368, 378, 381, 399, 420, 431, 434, 436, 437, 447, 452, 456, 460, 461, 480, 483, 503, 511, 523, 529, 530, 545, 582, 586, 626, 644, 653, 654, 692, 766, 784, 790, 800, 805, 817, 823, 827, 849, 863, 876, 892, 906, 907, 921, 936, 938, 942, 949, 960, 984, 987, 988, 992, 836, 499, 633, 88, 99, 138, 143, 181, 226, 236, 253, 283, 286, 306, 316, 318, 323, 599, 625, 671, 730, 731, 779, 816, 953])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([319])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degraded_cls_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "degraded_cls = degraded_cls_list[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([266, 193, 250, 660, 764, 620, 380, 409, 676, 887, 928, 975, 171, 311,\n",
       "        377, 857, 101,  46, 543, 559, 579, 803, 813, 885,  32, 748,  63, 142,\n",
       "        161, 186, 402, 629, 868, 878, 908, 233, 249, 304, 489, 506, 600, 696,\n",
       "        812, 814, 911, 923,  26,  77, 134, 202])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degraded_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(len(degraded_cls)).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
