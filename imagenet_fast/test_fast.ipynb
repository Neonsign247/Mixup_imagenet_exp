{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_paths\n",
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "import math\n",
    "import numpy as np\n",
    "from utils import *\n",
    "from validation import validate\n",
    "#import torchvision.models as models\n",
    "import models\n",
    "from models.imagenet_resnet import BasicBlock, Bottleneck\n",
    "from multiprocessing import Pool\n",
    "#from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "import pdb\n",
    "import wandb\n",
    "\n",
    "from apex import amp\n",
    "import copy\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4,5,6,7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_width = 192\n",
    "\n",
    "TOTAL_BAR_LENGTH = 65.\n",
    "last_time = time.time()\n",
    "begin_time = last_time\n",
    "\n",
    "def progress_bar(current, total, msg=None):\n",
    "    global last_time, begin_time\n",
    "    if current == 0:\n",
    "        begin_time = time.time()  # Reset for new bar.\n",
    "\n",
    "    cur_len = int(TOTAL_BAR_LENGTH*current/total)\n",
    "    rest_len = int(TOTAL_BAR_LENGTH - cur_len) - 1\n",
    "\n",
    "    sys.stdout.write(' [')\n",
    "    for i in range(cur_len):\n",
    "        sys.stdout.write('=')\n",
    "    sys.stdout.write('>')\n",
    "    for i in range(rest_len):\n",
    "        sys.stdout.write('.')\n",
    "    sys.stdout.write(']')\n",
    "\n",
    "    cur_time = time.time()\n",
    "    step_time = cur_time - last_time\n",
    "    last_time = cur_time\n",
    "    tot_time = cur_time - begin_time\n",
    "\n",
    "    L = []\n",
    "    L.append('  Step: %s' % format_time(step_time))\n",
    "    L.append(' | Tot: %s' % format_time(tot_time))\n",
    "    if msg:\n",
    "        L.append(' | ' + msg)\n",
    "\n",
    "    msg = ''.join(L)\n",
    "    sys.stdout.write(msg)\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH)-len(msg)-3):\n",
    "        sys.stdout.write(' ')\n",
    "\n",
    "    # Go back to the center of the bar.\n",
    "    for i in range(term_width-int(TOTAL_BAR_LENGTH/2)+2):\n",
    "        sys.stdout.write('\\b')\n",
    "    sys.stdout.write(' %d/%d ' % (current+1, total))\n",
    "\n",
    "    if current < total-1:\n",
    "        sys.stdout.write('\\r')\n",
    "    else:\n",
    "        sys.stdout.write('\\n')\n",
    "    sys.stdout.flush()\n",
    "\n",
    "\n",
    "def format_time(seconds):\n",
    "    days = int(seconds / 3600/24)\n",
    "    seconds = seconds - days*3600*24\n",
    "    hours = int(seconds / 3600)\n",
    "    seconds = seconds - hours*3600\n",
    "    minutes = int(seconds / 60)\n",
    "    seconds = seconds - minutes*60\n",
    "    secondsf = int(seconds)\n",
    "    seconds = seconds - secondsf\n",
    "    millis = int(seconds*1000)\n",
    "\n",
    "    f = ''\n",
    "    i = 1\n",
    "    if days > 0:\n",
    "        f += str(days) + 'D'\n",
    "        i += 1\n",
    "    if hours > 0 and i <= 2:\n",
    "        f += str(hours) + 'h'\n",
    "        i += 1\n",
    "    if minutes > 0 and i <= 2:\n",
    "        f += str(minutes) + 'm'\n",
    "        i += 1\n",
    "    if secondsf > 0 and i <= 2:\n",
    "        f += str(secondsf) + 's'\n",
    "        i += 1\n",
    "    if millis > 0 and i <= 2:\n",
    "        f += str(millis) + 'ms'\n",
    "        i += 1\n",
    "    if f == '':\n",
    "        f = '0ms'\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'resnet50'\n"
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "arch = 'resnet50'\n",
    "print(\"=> creating model '{}'\".format(arch))\n",
    "model = models.__dict__[arch]()\n",
    "numberofclass = 1000\n",
    "\n",
    "def init_dist_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, BasicBlock):\n",
    "            m.bn2.weight = nn.Parameter(torch.zeros_like(m.bn2.weight))\n",
    "        if isinstance(m, Bottleneck):\n",
    "            m.bn3.weight = nn.Parameter(torch.zeros_like(m.bn3.weight))\n",
    "        if isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0, 0.01)\n",
    "\n",
    "init_dist_weights(model)\n",
    "# Wrap the model into DataParallel\n",
    "model.cuda()\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "valdir = os.path.join('/workspace/dataset/ILSVRC2012/val')\n",
    "valdir = os.path.join('/workspace/dataset/ILSVRC2012-sz/352/val')\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    datasets.ImageFolder(valdir, transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ])),\n",
    "    batch_size=512, shuffle=False,\n",
    "    num_workers=10, pin_memory=True)\n",
    "\n",
    "\n",
    "# # Initiate data loaders\n",
    "# data = '/workspace/dataset/ILSVRC2012-sz/352'\n",
    "# crop_size = 224\n",
    "# min_scale = 0.087\n",
    "# batch_size = 448\n",
    "# workers = 10\n",
    "# traindir = os.path.join(data, 'train')\n",
    "# valdir = os.path.join(data, 'val')\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(crop_size, scale=(min_scale, 1.0)),\n",
    "#     transforms.RandomHorizontalFlip(),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# test_transform = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# train_dataset = datasets.ImageFolder(traindir, train_transform)\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "#                                            batch_size=batch_size,\n",
    "#                                            shuffle=True,\n",
    "#                                            num_workers=workers,\n",
    "#                                            pin_memory=True,\n",
    "#                                            sampler=None,\n",
    "#                                            drop_last=True)\n",
    "\n",
    "# val_loader = torch.utils.data.DataLoader(datasets.ImageFolder(valdir, test_transform),\n",
    "#                                          batch_size=batch_size,\n",
    "#                                          shuffle=False,\n",
    "#                                          num_workers=workers,\n",
    "#                                          pin_memory=True,\n",
    "#                                          drop_last=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'trained_models/mixup_1_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/mixup_1_phase3/model_best.pth.tar' (epoch 93)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 75.63399505615234\n",
      " [================================================================>]  Step: 219ms | Tot: 28s133ms | eval                                                                                       98/98 \n",
      "=> loading checkpoint 'trained_models/mixup_2_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/mixup_2_phase3/model_best.pth.tar' (epoch 95)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 75.8759994506836\n",
      " [================================================================>]  Step: 235ms | Tot: 27s994ms | eval                                                                                       98/98                                                                                  52/98 \n",
      "=> loading checkpoint 'trained_models/mixup_3_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/mixup_3_phase3/model_best.pth.tar' (epoch 100)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 75.93399810791016\n",
      " [===============================================================>.]  Step: 223ms | Tot: 27s964ms | eval                                                                                       97/98 ================================>]  Step: 200ms | Tot: 28s165ms | eval                                                                                       98/98 \n",
      "=> loading checkpoint 'trained_models/mixup_4_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/mixup_4_phase3/model_best.pth.tar' (epoch 93)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 75.93599700927734\n",
      " [================================================================>]  Step: 206ms | Tot: 27s899ms | eval                                                                                       98/98 \n",
      "=> loading checkpoint 'trained_models/mixup_5_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/mixup_5_phase3/model_best.pth.tar' (epoch 96)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 75.74048614501953\n",
      " [================================================================>]  Step: 212ms | Tot: 28s124ms | eval                                                                                       98/98                                                                 62/98 64/98 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([75.64 , 75.874, 75.936, 75.936, 75.73 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_samples = 5\n",
    "\n",
    "correct_classes_all = torch.zeros(exp_samples, numberofclass, dtype=int).cuda()\n",
    "number_classes_all = torch.zeros(exp_samples, numberofclass, dtype=int).cuda()\n",
    "\n",
    "for exp in [\n",
    "    'mixup_'\n",
    "#     'cutmix_d0.2_'\n",
    "#     'cutmix',\n",
    "#     'cutmix_d0.1_',\n",
    "#     'cutmix_d25_'\n",
    "]:\n",
    "    for j in range(exp_samples):\n",
    "        expname = exp + str(j+1)\n",
    "        resume = 'trained_models/' + expname + '_phase3/model_best.pth.tar'\n",
    "        if os.path.isfile(resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "            checkpoint = torch.load(resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "    #         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\".format(resume,\n",
    "                                                                checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "            break\n",
    "\n",
    "        print('the number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "        print('best prec1: {}'.format(best_prec1))\n",
    "\n",
    "        # define loss function (criterion) and optimizer\n",
    "        criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        cudnn.benchmark = True\n",
    "        correct_classes = torch.zeros(numberofclass, dtype=int).cuda()\n",
    "        number_classes = torch.zeros(numberofclass, dtype=int).cuda()\n",
    "\n",
    "        # switch to evaluate mode\n",
    "        model.eval()\n",
    "\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            target = target.cuda()\n",
    "\n",
    "            output = model(input)\n",
    "            output = output.data\n",
    "            topk=(1,)\n",
    "\n",
    "            maxk = max(topk)\n",
    "            batch_size = target.size(0)\n",
    "\n",
    "            _, pred = output.topk(maxk, 1, True, True)\n",
    "            pred = pred.t()\n",
    "            correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "            for c, n in zip(correct.reshape(-1).int(), target):\n",
    "                correct_classes[n] += c\n",
    "                number_classes[n] += 1\n",
    "            progress_bar(i, len(val_loader), 'eval')\n",
    "        correct_classes_all[j] = correct_classes\n",
    "        number_classes_all[j] = number_classes\n",
    "    np.save('npy/correct_classes_all_{0}'.format(exp), correct_classes_all.cpu().numpy())\n",
    "    np.save('npy/number_classes_all_{0}'.format(exp), number_classes_all.cpu().numpy())\n",
    "    \n",
    "correct_classes_all_n = correct_classes_all.cpu().numpy()\n",
    "number_classes_all_n = number_classes_all.cpu().numpy()\n",
    "class_accuracy = correct_classes_all_n/number_classes_all_n*100\n",
    "np.average(class_accuracy, axis=1)    \n",
    "#     np.savetxt('recall/' + expname + '_val.csv', np.transpose(np.stack((correct_classes, number_classes, correct_classes/number_classes))), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'trained_models/vanilla1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/vanilla1/model_best.pth.tar' (epoch 100)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.15447235107422\n",
      " [================================================================>]  Step: 6s906ms | Tot: 1m1s | eval                                                                                         98/98 \n",
      "=> loading checkpoint 'trained_models/vanilla2/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/vanilla2/model_best.pth.tar' (epoch 87)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.23047637939453\n",
      " [================================================================>]  Step: 394ms | Tot: 1m9s | eval                                                                                           98/98 \n",
      "=> loading checkpoint 'trained_models/vanilla3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/vanilla3/model_best.pth.tar' (epoch 99)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.15447235107422\n",
      " [================================================================>]  Step: 346ms | Tot: 51s873ms | eval                                                                                       98/98 \n",
      "=> loading checkpoint 'trained_models/vanilla4/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/vanilla4/model_best.pth.tar' (epoch 92)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.31246948242188\n",
      " [================================================================>]  Step: 304ms | Tot: 53s103ms | eval                                                                                       98/98 \n",
      "=> loading checkpoint 'trained_models/vanilla5/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/vanilla5/model_best.pth.tar' (epoch 99)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.34046936035156\n",
      " [================================================================>]  Step: 480ms | Tot: 53s357ms | eval                                                                                       98/98 \n"
     ]
    }
   ],
   "source": [
    "exp_samples = 5\n",
    "\n",
    "correct_classes_all = torch.zeros(exp_samples, numberofclass, dtype=int).cuda()\n",
    "number_classes_all = torch.zeros(exp_samples, numberofclass, dtype=int).cuda()\n",
    "\n",
    "for exp in [\n",
    "    'cutmix',\n",
    "    'cutmix_d0.1_'\n",
    "]:\n",
    "    for j in range(exp_samples):\n",
    "        expname = exp + str(j+1)\n",
    "        resume = 'trained_models/' + expname + '_phase3/model_best.pth.tar'\n",
    "        if os.path.isfile(resume):\n",
    "            print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "            checkpoint = torch.load(resume)\n",
    "            start_epoch = checkpoint['epoch']\n",
    "            best_prec1 = checkpoint['best_prec1']\n",
    "            model.load_state_dict(checkpoint['state_dict'])\n",
    "    #         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "            print(\"=> loaded checkpoint '{}' (epoch {})\".format(resume,\n",
    "                                                                checkpoint['epoch']))\n",
    "        else:\n",
    "            print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "\n",
    "        print('the number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "        print('best prec1: {}'.format(best_prec1))\n",
    "\n",
    "        # define loss function (criterion) and optimizer\n",
    "        criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "        cudnn.benchmark = True\n",
    "        correct_classes = torch.zeros(numberofclass, dtype=int).cuda()\n",
    "        number_classes = torch.zeros(numberofclass, dtype=int).cuda()\n",
    "\n",
    "        # switch to evaluate mode\n",
    "        model.eval()\n",
    "\n",
    "        end = time.time()\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            target = target.cuda()\n",
    "\n",
    "            output = model(input)\n",
    "            output = output.data\n",
    "            topk=(1,)\n",
    "\n",
    "            maxk = max(topk)\n",
    "            batch_size = target.size(0)\n",
    "\n",
    "            _, pred = output.topk(maxk, 1, True, True)\n",
    "            pred = pred.t()\n",
    "            correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "            for c, n in zip(correct.reshape(-1).int(), target):\n",
    "                correct_classes[n] += c\n",
    "                number_classes[n] += 1\n",
    "            progress_bar(i, len(val_loader), 'eval')\n",
    "        correct_classes_all[j] = correct_classes\n",
    "        number_classes_all[j] = number_classes\n",
    "    np.save('npy/correct_classes_all_{0}'.format(exp), correct_classes_all.cpu().numpy())\n",
    "    np.save('npy/number_classes_all_{0}'.format(exp), number_classes_all.cpu().numpy())\n",
    "    \n",
    "correct_classes_all_n = correct_classes_all.cpu().numpy()\n",
    "number_classes_all_n = number_classes_all.cpu().numpy()\n",
    "class_accuracy = correct_classes_all_n/number_classes_all_n*100\n",
    "np.average(class_accuracy, axis=1)    \n",
    "#     np.savetxt('recall/' + expname + '_val.csv', np.transpose(np.stack((correct_classes, number_classes, correct_classes/number_classes))), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([76.126, 76.212, 76.128, 76.272, 76.34 ])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classes_all_n = correct_classes_all.cpu().numpy()\n",
    "number_classes_all_n = number_classes_all.cpu().numpy()\n",
    "class_accuracy = correct_classes_all_n/number_classes_all_n*100\n",
    "np.average(class_accuracy, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead. (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:81.)\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-2b6b40a0a959>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclass_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect_classes_all\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnumber_classes_all\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mclass_accuracy_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_accuracy_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cutmix'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_class_accuracy_avg.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_accuracy_avg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_accuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36maverage\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36maverage\u001b[0;34m(a, axis, weights, returned)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m         \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0mscl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mavg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;31m# Make this warning show up first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mitems\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "class_accuracy_avg = np.average(class_accuracy.cpu(), axis=1)\n",
    "accuracy = np.average(class_accuracy_avg, axis=2)\n",
    "np.savetxt('cutmix' + method + '_class_accuracy_avg.csv', class_accuracy_avg[:, 1, :], delimiter=',')\n",
    "np.std(np.average(class_accuracy.cpu(), axis=3), axis=1), np.average(np.average(class_accuracy.cpu(), axis=3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'trained_models/cutmix_d150_randomseed_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d150_randomseed_phase3/model_best.pth.tar' (epoch 100)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 72.4020004272461\n",
      " [================================================================>]  Step: 111ms | Tot: 26s361ms | eval                                                                                       98/98              15/98 ...........................]  Step: 198ms | Tot: 6s711ms | eval                                                                                        17/9 18/98 25/9 26/9 27/98 28/98 ........................................]  Step: 266ms | Tot: 10s143ms | eval                                                                                       29/98                                                    54/98 68/98 70/98 71/98 \n",
      " Final Prec@1 72.398 Prec@5 91.824\n"
     ]
    }
   ],
   "source": [
    "for exp in [\n",
    "#     'cutmix_d50_phase3',\n",
    "#     'cutmix_d100_phase3',  \n",
    "#     'cutmix_d50_phase3',\n",
    "#     'cutmix_d200_phase3',\n",
    "#     'cutmix_d250_phase3'\n",
    "#     'cutmix_d0.1_randomseed_phase3',\n",
    "#     'cutmix_d1.0_randomseed2_phase3',\n",
    "#     'cutmix_d0.0_randomseed_phase3',\n",
    "#     'cutmix_d1.0_randomseed_phase3'\n",
    "#     'cutmix_d0.2_randomseed_phase3',\n",
    "#     'cutmix_d0.3_randomseed_phase3',\n",
    "#     'cutmix_d0.4_randomseed_phase3',\n",
    "#     'cutmix_d0.5_randomseed_phase3'\n",
    "#     'cutmix_d0.6_randomseed_phase3',\n",
    "#     'cutmix_d0.7_randomseed_phase3',\n",
    "#     'cutmix_d0.8_randomseed_phase3',\n",
    "#     'cutmix_d0.9_randomseed_phase3'\n",
    "#     'cutmix_d150_phase3_109',\n",
    "#     'cutmix_d75_phase3_109'\n",
    "#     'cutmix_d225_phase3_61',\n",
    "#     'cutmix_d25_phase3_109'\n",
    "#     'cutmix_d100_randomseed_phase3',  \n",
    "#     'cutmix_d50_randomseed_phase3',\n",
    "#     'cutmix_d200_randomseed_phase3',\n",
    "    'cutmix_d150_randomseed_phase3'\n",
    "#     'cutmix_d50_phase3_109'\n",
    "]:\n",
    "#             'cutmix_phase3',\n",
    "#             'vanilla_phase3',\n",
    "#             'cutmix_d0.0_phase3',\n",
    "#             'cutmix_d0.1_phase3',\n",
    "#             'cutmix_d0.3_phase3',\n",
    "#             'cutmix_d0.5_phase3',\n",
    "#             'cutmix_d0.6_phase3',\n",
    "#             'cutmix_d0.7_phase3',\n",
    "#             'cutmix_d0.8_phase3',\n",
    "#             'cutmix_d1.0_phase3']:\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    expname = exp\n",
    "#     resume = '../../Mixup_imagenet_exp_old/imagenet_fast/trained_models/' + expname + '/model_best.pth.tar'\n",
    "    resume = 'trained_models/' + expname + '/model_best.pth.tar'\n",
    "    if os.path.isfile(resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "        checkpoint = torch.load(resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(resume,\n",
    "                                                            checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "\n",
    "    print('the number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "    print('best prec1: {}'.format(best_prec1))\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    correct_classes = np.zeros(numberofclass, dtype=int)\n",
    "    number_classes = np.zeros(numberofclass, dtype=int)\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda()\n",
    "\n",
    "        output = model(input)\n",
    "        \n",
    "        prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        output = output.data\n",
    "        topk=(1,)\n",
    "\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        for c, n in zip(correct.reshape(-1).int(), target):\n",
    "            correct_classes[n] += c\n",
    "            number_classes[n] += 1\n",
    "\n",
    "        progress_bar(i, len(val_loader), 'eval')\n",
    "    print(' Final Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
    "    np.savetxt('recall/' + expname + '_val.csv', np.transpose(np.stack((correct_classes, number_classes, correct_classes/number_classes))), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'trained_models/cutmix_d0.3_phase3/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.3_phase3/model_best.pth.tar' (epoch 97)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 77.1719970703125\n",
      " [================================================================>]  Step: 110ms | Tot: 25s806ms | eval                                                                                       98/98 /98 ===================>...................]  Step: 200ms | Tot: 20s148ms | eval                                                                                       70/98                                             74/9 77/98 \n",
      " Final Prec@1 77.174 Prec@5 93.572\n"
     ]
    }
   ],
   "source": [
    "for exp in [\n",
    "#             'cutmix_phase3',\n",
    "#             'vanilla_phase3',\n",
    "#             'cutmix_d0.0_phase3',\n",
    "#             'cutmix_d0.1_phase3',\n",
    "            'cutmix_d0.3_phase3'\n",
    "#             'cutmix_d0.5_phase3',\n",
    "#             'cutmix_d0.6_phase3',\n",
    "#             'cutmix_d0.7_phase3',\n",
    "#             'cutmix_d0.8_phase3',\n",
    "#             'cutmix_d1.0_phase3'\n",
    "]:\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "    expname = exp\n",
    "#     resume = '../../Mixup_imagenet_exp_old/imagenet_fast/trained_models/' + expname + '/model_best.pth.tar'\n",
    "    resume = 'trained_models/' + expname + '/model_best.pth.tar'\n",
    "    if os.path.isfile(resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "        checkpoint = torch.load(resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(resume,\n",
    "                                                            checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "\n",
    "    print('the number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "    print('best prec1: {}'.format(best_prec1))\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    correct_classes = np.zeros(numberofclass, dtype=int)\n",
    "    number_classes = np.zeros(numberofclass, dtype=int)\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda()\n",
    "\n",
    "        output = model(input)\n",
    "        \n",
    "        prec1, prec5 = accuracy(output, target, topk=(1, 5))\n",
    "        top1.update(prec1[0], input.size(0))\n",
    "        top5.update(prec5[0], input.size(0))\n",
    "\n",
    "        output = output.data\n",
    "        topk=(1,)\n",
    "\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        for c, n in zip(correct.reshape(-1).int(), target):\n",
    "            correct_classes[n] += c\n",
    "            number_classes[n] += 1\n",
    "\n",
    "        progress_bar(i, len(val_loader), 'eval')\n",
    "    print(' Final Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
    "    np.savetxt('recall/' + expname + '_val.csv', np.transpose(np.stack((correct_classes, number_classes, correct_classes/number_classes))), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading checkpoint 'trained_models/cutmix_d0.0_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.0_phase1/model_best.pth.tar' (epoch 100)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 77.19400024414062\n",
      " [================================================================>]  Step: 120ms | Tot: 36s842ms | eval                                                                                       98/98 98 9/9 18/98 .....]  Step: 193ms | Tot: 18s27ms | eval                                                                                        39/98                                  40/9 62/98                                                                       69/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.1_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.1_phase1/model_best.pth.tar' (epoch 94)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.9964599609375\n",
      " [================================================================>]  Step: 117ms | Tot: 23s387ms | eval                                                                                       98/98 37/98                                                      55/98 ====================>.......................]  Step: 204ms | Tot: 15s568ms | eval                                                                                       64/98 ================================>.............]  Step: 198ms | Tot: 18s804ms | eval                                                                                       78/98 79/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.2_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.2_phase1/model_best.pth.tar' (epoch 100)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 77.11245727539062\n",
      " [================================================================>]  Step: 110ms | Tot: 24s463ms | eval                                                                                       98/98              38/98 ====================================================>.....]  Step: 197ms | Tot: 23s418ms | eval                                                                                       91/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.3_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.3_phase1/model_best.pth.tar' (epoch 89)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.91600036621094\n",
      " [================================================================>]  Step: 115ms | Tot: 33s520ms | eval                                                                                       98/98 98                     12/9 39/98 77/98 =================================>.....]  Step: 195ms | Tot: 32s215ms | eval                                                                                       90/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.4_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.4_phase1/model_best.pth.tar' (epoch 96)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.74446105957031\n",
      " [================================================================>]  Step: 179ms | Tot: 24s82ms | eval                                                                                        98/98 ...........................................................]  Step: 198ms | Tot: 1s80ms | eval                                                                                         7/98                                                       16/98                                                                                      58/98 =============>.................]  Step: 195ms | Tot: 18s222ms | eval                                                                                       73/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.5_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.5_phase1/model_best.pth.tar' (epoch 96)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 76.1240005493164\n",
      " [================================================================>]  Step: 119ms | Tot: 23s643ms | eval                                                                                       98/98                                               8/98 ]  Step: 199ms | Tot: 3s625ms | eval                                                                                        19/98 ...............................]  Step: 232ms | Tot: 5s887ms | eval                                                                                        26/98 ...................]  Step: 199ms | Tot: 14s563ms | eval                                                                                       59/98                                                               65/98 ...]  Step: 197ms | Tot: 16s245ms | eval                                                                                       67/98 ==============================>...............]  Step: 254ms | Tot: 18s415ms | eval                                                                                       76/9 84/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.6_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.6_phase1/model_best.pth.tar' (epoch 98)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 75.86199951171875\n",
      " [================================================================>]  Step: 123ms | Tot: 23s443ms | eval                                                                                       98/98 /98                                                                            36/9 45/98                                                                                      50/98                                     69 70/98 90/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.7_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.7_phase1/model_best.pth.tar' (epoch 99)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 75.40599822998047\n",
      " [================================================================>]  Step: 119ms | Tot: 24s215ms | eval                                                                                       98/98 42/9 56/98  57/9 64/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.8_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.8_phase1/model_best.pth.tar' (epoch 66)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 74.82250213623047\n",
      " [================================================================>]  Step: 111ms | Tot: 22s836ms | eval                                                                                       98/98                                                                     17/9 55/98                                                                                  90/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d0.9_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d0.9_phase1/model_best.pth.tar' (epoch 65)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 74.30400085449219\n",
      " [================================================================>]  Step: 119ms | Tot: 22s807ms | eval                                                                                       98/98 ................]  Step: 240ms | Tot: 3s201ms | eval                                                                                        14/9 22/98 ..........................]  Step: 198ms | Tot: 8s135ms | eval                                                                                        33/98 ======>.......................................]  Step: 200ms | Tot: 9s410ms | eval                                                                                        39/98 ====>......................................]  Step: 201ms | Tot: 9s770ms | eval                                                                                        41/98                                 47/98                                                                83/98 ======================================>..]  Step: 200ms | Tot: 22s321ms | eval                                                                                       95/98 \n",
      "=> loading checkpoint 'trained_models/cutmix_d1.0_phase1/model_best.pth.tar'\n",
      "=> loaded checkpoint 'trained_models/cutmix_d1.0_phase1/model_best.pth.tar' (epoch 67)\n",
      "the number of model parameters: 25557032\n",
      "best prec1: 73.38652801513672\n",
      " [================================================================>]  Step: 110ms | Tot: 22s790ms | eval                                                                                       98/98 /9 22/98                                                                 52/98                                       80/98 \n"
     ]
    }
   ],
   "source": [
    "for exp in range(0,11):\n",
    "    expname = 'cutmix_d' + str(exp/10)\n",
    "    resume = 'trained_models/' + expname + '_phase1/model_best.pth.tar'\n",
    "    if os.path.isfile(resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(resume))\n",
    "        checkpoint = torch.load(resume)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "#         optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(resume,\n",
    "                                                            checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(resume))\n",
    "\n",
    "    print('the number of model parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "    print('best prec1: {}'.format(best_prec1))\n",
    "\n",
    "    # define loss function (criterion) and optimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "    correct_classes = np.zeros(numberofclass, dtype=int)\n",
    "    number_classes = np.zeros(numberofclass, dtype=int)\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(val_loader):\n",
    "        target = target.cuda()\n",
    "\n",
    "        output = model(input)\n",
    "        output = output.data\n",
    "        topk=(1,)\n",
    "\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        for c, n in zip(correct.reshape(-1).int(), target):\n",
    "            correct_classes[n] += c\n",
    "            number_classes[n] += 1\n",
    "\n",
    "        progress_bar(i, len(val_loader), 'eval')\n",
    "    np.savetxt('recall/' + expname + '_val.csv', np.transpose(np.stack((correct_classes, number_classes, correct_classes/number_classes))), delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 1000]), torch.Size([256]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "numberofclass = 1000\n",
    "correct_classes = torch.empty(numberofclass, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8177e+31)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_classes[500][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "degraded_cls_list = torch.tensor([266, 193, 250, 660, 764, 620, 380, 409, 676, 887, 928, 975, 171, 311, 377, 857, 101, 46, 543, 559, 579, 803, 813, 885, 32, 748, 63, 142, 161, 186, 402, 629, 868, 878, 908, 233, 249, 304, 489, 506, 600, 696, 812, 814, 911, 923, 26, 77, 134, 202, 210, 243, 328, 382, 385, 473, 486, 522, 667, 711, 795, 797, 830, 902, 950, 68, 282, 415, 664, 838, 841, 860, 978, 999, 50, 184, 197, 383, 412, 457, 500, 507, 650, 693, 759, 778, 825, 844, 931, 939, 43, 81, 140, 165, 252, 297, 331, 345, 367, 379, 468, 546, 645, 726, 754, 756, 859, 864, 901, 972, 983, 4, 25, 115, 126, 152, 163, 204, 258, 259, 322, 442, 487, 538, 585, 589, 593, 596, 606, 617, 622, 710, 852, 914, 958, 990, 60, 73, 493, 567, 657, 848, 240, 44, 45, 71, 94, 158, 159, 178, 188, 199, 217, 288, 337, 349, 438, 466, 535, 578, 648, 678, 694, 735, 780, 786, 808, 880, 884, 980, 9, 90, 139, 182, 223, 230, 287, 295, 313, 356, 375, 448, 513, 708, 736, 740, 793, 799, 826, 856, 867, 889, 917, 918, 943, 7, 18, 23, 24, 34, 69, 74, 75, 78, 80, 82, 89, 92, 96, 97, 103, 116, 122, 131, 144, 157, 168, 174, 185, 194, 195, 213, 231, 234, 248, 261, 262, 272, 273, 274, 279, 284, 302, 307, 317, 338, 342, 343, 352, 354, 355, 368, 378, 381, 399, 420, 431, 434, 436, 437, 447, 452, 456, 460, 461, 480, 483, 503, 511, 523, 529, 530, 545, 582, 586, 626, 644, 653, 654, 692, 766, 784, 790, 800, 805, 817, 823, 827, 849, 863, 876, 892, 906, 907, 921, 936, 938, 942, 949, 960, 984, 987, 988, 992, 836, 499, 633, 88, 99, 138, 143, 181, 226, 236, 253, 283, 286, 306, 316, 318, 323, 599, 625, 671, 730, 731, 779, 816, 953])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([319])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degraded_cls_list.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "degraded_cls = degraded_cls_list[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([266, 193, 250, 660, 764, 620, 380, 409, 676, 887, 928, 975, 171, 311,\n",
       "        377, 857, 101,  46, 543, 559, 579, 803, 813, 885,  32, 748,  63, 142,\n",
       "        161, 186, 402, 629, 868, 878, 908, 233, 249, 304, 489, 506, 600, 696,\n",
       "        812, 814, 911, 923,  26,  77, 134, 202])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degraded_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(len(degraded_cls)).bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
